{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b5a396-2b93-44d9-aae3-332d282efb30",
   "metadata": {},
   "source": [
    "# Lab 2.2<br>Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9d1cf2-f9e0-4b84-918c-1a5c25ebb15f",
   "metadata": {},
   "source": [
    "## BUS152 - Spring 2024 <br> Brian Brady"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2249866d-8013-429e-8f2c-7a373df5cc30",
   "metadata": {},
   "source": [
    "### __Objectives__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eee8c4e-1b94-4cdd-8af0-959c2da15638",
   "metadata": {},
   "source": [
    "With this lesson we finally get a chance to pull in some real data!  There are lots of different ways you can connect to data, which will depend on whether you're in a production or development environment.  The reading material covers a wider array of accessibility, but for our purposes now we'll cover a few of the most common ways to get your hands dirty.  Our objectives for this lesson are to explore a few \n",
    "\n",
    "- Accessing Library Datasets\n",
    "- Downloading CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd35f1a-d8b3-480e-811e-f3a272a86d37",
   "metadata": {},
   "source": [
    "### __Accessing Library Datasets__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7a2f7c-124c-4486-a76a-d2f17a6def1a",
   "metadata": {},
   "source": [
    "This is probably the simplest way to get data to work with!  The are several libraries that have zipped up data and made available for us to download and use.  These are mainly datasets you can play with to learn, develop your model building skills, and to test alogrithm performance.  They are usually real-world data, however probably won't be the data you need for any real project you want to work on.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a135ac-adcb-4e8e-9f9f-91466e10cac9",
   "metadata": {},
   "source": [
    "If you have never installed the library you want to work with, then you will need to do this first before importing into your environment.  This is a one time step through the Anaconda Prompt, and you can proceed to the \"import\" command the next time.  To install, we would normally want to go through the anaconda package management system if possible, but often a library we want to work with won't be available there so we'll use the \"pip\" installer instead in those cases.  Try googling \"conda install *library name*\" and see if there's an option, if not, go ahead and use the `pip install *library name*` option instead.\n",
    "\n",
    "After you've installed the library, go ahead and run the `import` commands below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240abd2b-abb4-44e3-944f-2a298df4e768",
   "metadata": {},
   "source": [
    "![cond_prompt](../images/anaconda_prompt.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8ad411-5d39-4efd-bb90-a31139559e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from pydataset import data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ea5f59-c4b1-4c82-9815-b7220ca67117",
   "metadata": {},
   "source": [
    "Excellent.  Now you have the \"data\" function from the \"pydataset\" library loaded into your environment and available for use.\n",
    "\n",
    "So where to start with this one?   Don't worry, it's easy enough.  We can call the `data()` function and see the names and ids of all of the sets available for our use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfcdbbb-29c5-4a50-b3d7-85db1a1303ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off pandas truncation so we can see the entire list of datasets\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "display(data())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4356ac7-27f3-4a65-9230-51cd17634566",
   "metadata": {},
   "source": [
    "Ok, great.  See one that sounds like it might be fun to play with?  I do, so let's print the details for the \"income\" set with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a9aa58-73b7-4ee1-86b3-bceaee61546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the documentation for a given dataset\n",
    "data(\"income\", show_doc = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7f1912-c7d0-454f-9648-e8d8c02a2999",
   "metadata": {},
   "source": [
    "Awesome.  Sounds interesting.  Let's go ahead and read this one into memory and see what we've got!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d7f00d-e09d-4e3b-80b3-b218fd219fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the pandas truncation\n",
    "pd.set_option(\"display.max_rows\", 10)\n",
    "\n",
    "# Read in the \"income\" dataset\n",
    "dat = data('income')\n",
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172451fa-38b3-49b3-9645-ee66dbe1a33f",
   "metadata": {},
   "source": [
    "And there you go!  That's all there is to it for playing around with datasets from the `pydataset` library.  Go ahead and snoop around and see if you see any others that look interesting.  There are plenty of other libraries providing datasets too, but this one is a pretty decent sized and comprehensive list to get your started.  If you're looking for more, feel free to check out the `ucimlrepo` or `scikit-learn` datasets, among others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5255dd8f-4aaf-4b6b-ab15-4e0dfb82b95c",
   "metadata": {},
   "source": [
    "### __Downloading CSV Files__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa05ac9-db5f-47b6-9143-1e4c3ee9a944",
   "metadata": {},
   "source": [
    "This is probably the most common way you'll get real data once you move beyond playing around with toy sets in packaged libraries.  These can be files on your local machine, or off of shared sites like Google Drive or Github.\n",
    "\n",
    "Let's start with a local file on your machine.  If I'm working in a local IDE like Spyder or VS Code, normally I will go ahead and set my \"working directory\" using the `os.chdir()` function from the `os` library.  This is just a convenience step so your application knows where home base is for all of your files you're going to be working with importing and exporting.  Otherwise, you may need to point it to this folder manually each time you try to work with anything in this location.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1f6155-0b22-4fcb-b107-b9bbe1d801bd",
   "metadata": {},
   "source": [
    "Here's an example of a working directory path for my machine.  You'll need to update the `os.chdir()` path to wherever you cloned your course files from the Github repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db097d6e-b377-4203-b264-423ff436e02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your working directory\n",
    "import os\n",
    "import pandas as pd\n",
    "#os.chdir('D:/Brian/Althoff/BUS152-2024-Spring/datasets/')\n",
    "os.chdir('C:/your_path/BUS152-2024-Spring/datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce76ab1-ec7a-4f55-8c06-a05463ea8cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data using the pandas `pd.read_csv()` function\n",
    "dat = pd.read_csv(\"Davis.csv\")\n",
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2e43d8-7cf9-4ddf-9fb5-8cee96871c13",
   "metadata": {},
   "source": [
    "The pandas documentation is fantastic, so don't forget to check <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\">Pandas Read CSV</a> if you run into any issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc911ef0-e326-438b-ae73-bed5d498d794",
   "metadata": {},
   "source": [
    "This works just as well for datasets from cloud shared sites like Github.  See below and give it a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ef7ac8-da5e-4dfe-9d4c-c13de2d6487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Davis height/weight data from Github as a .csv file\n",
    "url = 'https://github.com/bradybr/practical-data-science-and-ml/blob/main/datasets/Davis.csv?raw=true'\n",
    "dat = pd.read_csv(url)\n",
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a1cad8-b655-454e-b512-02ef251bb92a",
   "metadata": {},
   "source": [
    "We're only just barely dipping our toe in the water here since this is all we'll need for our course, but there's so many more ways to get data that we don't have time to cover.  See <a href=\"https://bradybr.github.io/practical-data-science-and-ml/Chapter5/data_acquisition.html\">Chapter 5: Data Acquisition</a> for more detail."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
